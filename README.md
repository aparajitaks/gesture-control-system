# âœ‹ Gesture Control System

Real-time Hand Gesture Detection using **MediaPipe**, **FastAPI**, and **React**

A full-stack, real-time hand gesture detection system that uses a webcam to detect and classify hand gestures and streams results live to a web dashboard using **WebSockets**.

This project demonstrates real-time Computer Vision + Full Stack Web Development integration using a clean modular architecture.

---

## ğŸš€ Project Overview

The **Gesture Control System** captures a live webcam stream from the browser, sends frames to a FastAPI backend through WebSockets, processes hand landmarks using MediaPipe + OpenCV, and returns real-time gesture results back to the frontend dashboard.

This enables **low-latency live gesture detection** directly inside a modern React interface.

---

## âœ¨ Features

- âœ… Live camera feed inside browser  
- âœ… Real-time hand landmark detection using **MediaPipe**  
- âœ… Low-latency **WebSocket** based streaming  
- âœ… FastAPI backend for gesture processing  
- âœ… React + Vite frontend with modern UI  
- âœ… Modular backend architecture (scalable + clean)  
- âœ… Real-time dashboard updates  
- âœ… Backend health-check endpoint for monitoring  
- âœ… Easy to extend for more gestures / AI classification  

---

## ğŸ§  Tech Stack

### Frontend
- React (Vite)
- JavaScript (ES6+)
- HTML5 Video + Canvas
- WebSocket API

### Backend
- FastAPI
- Python 3.11
- WebSockets
- MediaPipe
- OpenCV

---

## ğŸ—ï¸ System Architecture

```text
Webcam
   â†“
Browser (React Frontend)
   â†“ WebSocket
FastAPI Backend
   â†“
MediaPipe + OpenCV
   â†“
Gesture Detection & Classification
   â†“ WebSocket Response
Live Dashboard Update

âš™ï¸ How to Run Locally
1ï¸âƒ£ Clone the Repository
git clone https://github.com/aparajitaks/gesture-control-system.git
cd gesture-control-system

2ï¸âƒ£ Backend Setup (FastAPI)
cd backend
python3.11 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
uvicorn app.main:app --reload --port 8000


Backend runs at:

ğŸ‘‰ http://localhost:8000

3ï¸âƒ£ Frontend Setup (React + Vite)

Open a new terminal:

cd frontend
npm install
npm run dev


Frontend runs at:

ğŸ‘‰ http://localhost:5173

ğŸŒ API Endpoints
Health Check
GET /health


Response:

{
  "status": "ok"
}

WebSocket Connection
/ws


Used for real-time video frame transfer + gesture response streaming.

ğŸ¥ Demo Video

ğŸ“Œ YouTube Demo:
https://www.youtube.com/watch?v=6uV31eVAnpI

ğŸ“‚ Folder Structure
gesture-control-system/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ websocket.py
â”‚   â”‚   â”œâ”€â”€ gesture_detector.py
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md (optional)
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â””â”€â”€ App.jsx
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”‚
â””â”€â”€ README.md

ğŸ¯ Learning Outcomes

Real-time WebSocket communication

MediaPipe hand landmark detection pipeline

Integrating React frontend with FastAPI backend

Debugging WebSocket lifecycle + streaming issues

Building scalable modular backend architecture

Practical real-time computer vision implementation

ğŸ”® Future Improvements

Add gesture-to-action mapping (volume, scrolling, app control)

Add ML-based gesture classification model

Improve UI dashboard analytics

Add multi-hand detection support

Deploy using Docker + Cloud hosting
